import pandas as pd
import matplotlib.pyplot as plt
import streamlit as st
import csv
from collections import Counter
from datetime import datetime

# ========== –õ–æ–≥–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ==========
def detect_delimiter(uploaded_file, num_lines=5):
    uploaded_file.seek(0)
    sample = ''.join([uploaded_file.readline().decode('utf-8', errors='ignore') for _ in range(num_lines)])
    uploaded_file.seek(0)  # –≤–µ—Ä–Ω—É—Ç—å —É–∫–∞–∑–∞—Ç–µ–ª—å —Ñ–∞–π–ª–∞ –≤ –Ω–∞—á–∞–ª–æ
    dialect = csv.Sniffer().sniff(sample)
    return dialect.delimiter

def preprocess(df):
    df = df.copy()
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º–æ–≥–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ –ø–æ —á–∞—Å—Ç–æ—Ç–µ '–û—Ç –∫–æ–≥–æ'
    senders = df['–û—Ç –∫–æ–≥–æ'].dropna().value_counts()
    probable_sender = senders.index[0] if not senders.empty else ""
    employee_name = probable_sender.split("<")[0].strip()
    # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤ —Å –¥–∞—Ç–∞–º–∏ –∫ —Ç–∏–ø—É datetime
    df['–î–∞—Ç–∞ –ø–æ–ª—É—á–µ–Ω–∏—è'] = pd.to_datetime(df['–î–∞—Ç–∞ –ø–æ–ª—É—á–µ–Ω–∏—è'], errors='coerce')
    df['–î–∞—Ç–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏'] = pd.to_datetime(df['–î–∞—Ç–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏'], errors='coerce')
    # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–º—ã –ø–∏—Å—å–º–∞ –æ—Ç –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤ "Re:"/"FW:"
    df['–¢–µ–º–∞ —á–∏—Å—Ç–∞—è'] = df['–¢–µ–º–∞'].str.lower().str.replace(r"^re:\s*|fw:\s*", "", regex=True).str.strip()
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–æ–ª–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ –≤ –ø–∏—Å—å–º–µ
    df['–†–æ–ª—å'] = df.apply(lambda row: (
        '–û—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å' if employee_name != "" and employee_name in str(row['–û—Ç –∫–æ–≥–æ']) else
        '–ü–æ–ª—É—á–∞—Ç–µ–ª—å' if employee_name != "" and employee_name in str(row['–ö–æ–º—É']) else
        '–í –∫–æ–ø–∏–∏'   if employee_name != "" and employee_name in str(row['–ö–æ–ø–∏—è']) else
        '–ù–µ —É–∫–∞–∑–∞–Ω–∞'), axis=1)
    # –í—ã–¥–µ–ª–µ–Ω–∏–µ –≥–æ–¥–∞, –Ω–æ–º–µ—Ä–∞ –Ω–µ–¥–µ–ª–∏ –∏ —á–∞—Å–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–∏—Å—å–º–∞
    df['–ì–æ–¥'] = df['–î–∞—Ç–∞ –ø–æ–ª—É—á–µ–Ω–∏—è'].dt.isocalendar().year
    df['–ù–µ–¥–µ–ª—è'] = df['–î–∞—Ç–∞ –ø–æ–ª—É—á–µ–Ω–∏—è'].dt.isocalendar().week
    df['–ß–∞—Å'] = df['–î–∞—Ç–∞ –ø–æ–ª—É—á–µ–Ω–∏—è'].dt.hour
    return df

def reply_time_analysis(df):
    import numpy as np
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –≤—Ö–æ–¥—è—â–∏–µ (–≥–¥–µ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–π —Å–æ—Ç—Ä—É–¥–Ω–∏–∫ ‚Äì –ø–æ–ª—É—á–∞—Ç–µ–ª—å) –∏ –∏—Å—Ö–æ–¥—è—â–∏–µ
    incoming = df[df['–†–æ–ª—å'] == '–ü–æ–ª—É—á–∞—Ç–µ–ª—å'].copy()
    outgoing = df[df['–†–æ–ª—å'] == '–û—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å'].copy()
    # –£–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∑–æ–Ω–µ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞ —Ä–∞–∑–Ω–∏—Ü—ã
    incoming['–î–∞—Ç–∞ –ø–æ–ª—É—á–µ–Ω–∏—è'] = incoming['–î–∞—Ç–∞ –ø–æ–ª—É—á–µ–Ω–∏—è'].dt.tz_localize(None)
    outgoing['–î–∞—Ç–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏'] = outgoing['–î–∞—Ç–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏'].dt.tz_localize(None)
    results = []
    for _, row in incoming.iterrows():
        # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –≤—Ö–æ–¥—è—â–µ–≥–æ –ø–∏—Å—å–º–∞ –∏—â–µ–º –∏—Å—Ö–æ–¥—è—â–µ–µ —Å —Ç–µ–º –∂–µ ConversationID, –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–µ –ø–æ–∑–∂–µ
        out_same_conv = outgoing[outgoing['ConversationID'] == row['ConversationID']]
        after = out_same_conv[out_same_conv['–î–∞—Ç–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏'] > row['–î–∞—Ç–∞ –ø–æ–ª—É—á–µ–Ω–∏—è']]
        if not after.empty:
            soonest = after.sort_values('–î–∞—Ç–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏').iloc[0]
            delta_hours = (soonest['–î–∞—Ç–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏'] - row['–î–∞—Ç–∞ –ø–æ–ª—É—á–µ–Ω–∏—è']).total_seconds() / 3600
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—á–∏—Ö –¥–Ω–µ–π –º–µ–∂–¥—É –¥–∞—Ç–∞–º–∏ (np.busday_count —É—á–∏—Ç—ã–≤–∞–µ—Ç –±—É–¥–Ω–∏)
            start = row['–î–∞—Ç–∞ –ø–æ–ª—É—á–µ–Ω–∏—è'].date()
            end = soonest['–î–∞—Ç–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏'].date()
            business_days = np.busday_count(start, end)
            results.append({
                'ConversationID': row['ConversationID'],
                '–ù–µ–¥–µ–ª—è': row['–ù–µ–¥–µ–ª—è'],
                '–¢–µ–º–∞': row['–¢–µ–º–∞'],
                '–î–∞—Ç–∞ –≤—Ö–æ–¥—è—â–µ–≥–æ': row['–î–∞—Ç–∞ –ø–æ–ª—É—á–µ–Ω–∏—è'],
                '–î–∞—Ç–∞ –æ—Ç–≤–µ—Ç–∞': soonest['–î–∞—Ç–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏'],
                '–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞': delta_hours,
                '–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ (–¥–Ω–µ–π)': round(delta_hours / 24, 2),
                '–†–∞–±–æ—á–∏—Ö –¥–Ω–µ–π –¥–æ –æ—Ç–≤–µ—Ç–∞': business_days,
                '–ü—Ä–æ—Å—Ä–æ—á–∫–∞': business_days > 3
            })
    return pd.DataFrame(results)

def plot_reply_distribution(reply_times):
    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞ (–æ—Ç—Å–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –±–æ–ª—å—à–µ 7 –¥–Ω–µ–π/168 —á–∞—Å–æ–≤)
    clean_times = [t for t in reply_times if t <= 168]
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.hist(clean_times, bins=30, edgecolor='black')
    ax.set_xticks(range(0, 169, 24))
    ax.set_title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞ (–¥–æ 7 –¥–Ω–µ–π)")
    ax.set_xlabel("–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞, —á–∞—Å—ã")
    ax.set_ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏—Å–µ–º")
    return fig

def plot_weekly_trends(reply_df):
    # –°—Ä–µ–¥–Ω–µ–µ –∏ –º–µ–¥–∏–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ –ø–æ –Ω–µ–¥–µ–ª—è–º
    summary = reply_df.groupby('–ù–µ–¥–µ–ª—è')['–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞'].agg(['mean', 'median'])
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.plot(summary.index, summary['mean'], marker='o', label='–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è')
    ax.plot(summary.index, summary['median'], marker='s', label='–ú–µ–¥–∏–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è')
    ax.set_title("–°—Ä–µ–¥–Ω–µ–µ –∏ –º–µ–¥–∏–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ –ø–æ –Ω–µ–¥–µ–ª—è–º")
    ax.set_xlabel("–ù–µ–¥–µ–ª—è")
    ax.set_ylabel("–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞, —á–∞—Å—ã")
    ax.legend()
    ax.grid(True)
    return fig

def plot_weekly_message_flow(df):
    # –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω—ã–π –ø–æ—Ç–æ–∫ –ø–∏—Å–µ–º: –ø–æ–ª—É—á–µ–Ω–æ vs –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ
    weekly = df[df['–†–æ–ª—å'].isin(['–û—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å', '–ü–æ–ª—É—á–∞—Ç–µ–ª—å'])]
    pivot = weekly.pivot_table(index='–ù–µ–¥–µ–ª—è', columns='–†–æ–ª—å', aggfunc='size', fill_value=0)
    # –ü—Ä–æ—Ü–µ–Ω—Ç –æ—Ç–≤–µ—Ç–æ–≤ (–∏—Å—Ö–æ–¥—è—â–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –≤—Ö–æ–¥—è—â–∏—Ö) –ø–æ –Ω–µ–¥–µ–ª—è–º
    pivot['–ü—Ä–æ—Ü–µ–Ω—Ç –æ—Ç–≤–µ—Ç–æ–≤'] = (pivot['–û—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å'] / pivot['–ü–æ–ª—É—á–∞—Ç–µ–ª—å'] * 100).round(1)
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.bar(range(len(pivot.index)), pivot['–ü–æ–ª—É—á–∞—Ç–µ–ª—å'], width=0.4, label='–ü–æ–ª—É—á–µ–Ω–æ')
    ax.bar([i + 0.4 for i in range(len(pivot.index))], pivot['–û—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å'], width=0.4, label='–û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ')
    # –ü–æ–¥–ø–∏—Å–∏ –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –Ω–∞–¥ —Å—Ç–æ–ª–±–∏–∫–∞–º–∏
    for i, week in enumerate(pivot.index):
        ax.text(i, max(pivot.iloc[i]['–ü–æ–ª—É—á–∞—Ç–µ–ª—å'], pivot.iloc[i]['–û—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å']) + 1,
                f"{pivot.iloc[i]['–ü—Ä–æ—Ü–µ–Ω—Ç –æ—Ç–≤–µ—Ç–æ–≤']}%", ha='center', fontsize=9)
    ax.set_xticks(range(len(pivot.index)))
    ax.set_xticklabels(pivot.index)
    ax.set_title("–û–±—ä–µ–º –≤—Ö–æ–¥—è—â–∏—Ö –∏ –∏—Å—Ö–æ–¥—è—â–∏—Ö –ø–∏—Å–µ–º –ø–æ –Ω–µ–¥–µ–ª—è–º")
    ax.set_xlabel("–ù–µ–¥–µ–ª—è")
    ax.set_ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏—Å–µ–º")
    ax.legend()
    ax.grid(axis='y')
    return fig

def plot_weekly_claims(df):
    # –ê–Ω–∞–ª–∏–∑ –ø–∏—Å–µ–º —Å —Ç–µ–º–æ–π "—Ä–µ–∫–ª–∞–º–∞—Ü–∏—è" –ø–æ –Ω–µ–¥–µ–ª—è–º
    df['–†–µ–∫–ª–∞–º–∞—Ü–∏—è'] = df['–¢–µ–º–∞'].str.lower().str.contains("—Ä–µ–∫–ª–∞–º–∞—Ü–∏—è")
    weekly_claims = df.groupby(['–ù–µ–¥–µ–ª—è', '–†–µ–∫–ª–∞–º–∞—Ü–∏—è']).size().unstack(fill_value=0)
    # –ü–µ—Ä–µ–∏–º–µ–Ω—É–µ–º —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è —è—Å–Ω–æ—Å—Ç–∏
    if True in weekly_claims.columns:
        weekly_claims.columns = ['–ë–µ–∑ —Ä–µ–∫–ª–∞–º–∞—Ü–∏–∏', '–° —Ä–µ–∫–ª–∞–º–∞—Ü–∏–µ–π']
    else:
        weekly_claims.columns = ['–ë–µ–∑ —Ä–µ–∫–ª–∞–º–∞—Ü–∏–∏']
    fig, ax = plt.subplots(figsize=(10, 5))
    bar_width = 0.4
    weeks = weekly_claims.index
    x = range(len(weeks))
    # –°—Ç–æ–ª–±–∏–∫–∏ –¥–ª—è –ø–∏—Å–µ–º –±–µ–∑ —Ä–µ–∫–ª–∞–º–∞—Ü–∏–π –∏ —Å —Ä–µ–∫–ª–∞–º–∞—Ü–∏—è–º–∏
    ax.bar([i - bar_width/2 for i in x], weekly_claims['–ë–µ–∑ —Ä–µ–∫–ª–∞–º–∞—Ü–∏–∏'], width=bar_width, label='–ë–µ–∑ —Ä–µ–∫–ª–∞–º–∞—Ü–∏–∏')
    if '–° —Ä–µ–∫–ª–∞–º–∞—Ü–∏–µ–π' in weekly_claims.columns:
        ax.bar([i + bar_width/2 for i in x], weekly_claims['–° —Ä–µ–∫–ª–∞–º–∞—Ü–∏–µ–π'], width=bar_width, label='–° —Ä–µ–∫–ª–∞–º–∞—Ü–∏–µ–π')
    ax.set_xticks(x)
    ax.set_xticklabels(weeks)
    ax.set_title("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏—Å–µ–º —Å —Ç–µ–º–æ–π '—Ä–µ–∫–ª–∞–º–∞—Ü–∏—è' –ø–æ –Ω–µ–¥–µ–ª—è–º")
    ax.set_xlabel("–ù–µ–¥–µ–ª—è")
    ax.set_ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏—Å–µ–º")
    ax.legend()
    ax.grid(axis='y')
    return fig

def stretch_topics(df):
    # –í—ã—è–≤–ª–µ–Ω–∏–µ "—Ä–∞—Å—Ç—è–Ω—É—Ç—ã—Ö" —Ç–µ–º –ø–µ—Ä–µ–ø–∏—Å–∫–∏ (–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é 20+ –¥–Ω–µ–π) –ø–æ ConversationID
    stretched_list = []
    # –†–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–ø–∏—Å–∫–∏, –≥–¥–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫ —É—á–∞—Å—Ç–≤–æ–≤–∞–ª –∫–∞–∫ –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å
    conv_with_outgoing = set(df[df['–†–æ–ª—å'] == '–û—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å']['ConversationID'].unique())
    for conv_id, group in df.groupby('ConversationID'):
        if conv_id not in conv_with_outgoing:
            continue
        # –£–±–∏—Ä–∞–µ–º tz-–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –¥–∞—Ç –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        try:
            group['–î–∞—Ç–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏'] = group['–î–∞—Ç–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏'].dt.tz_localize(None)
        except:
            pass
        try:
            group['–î–∞—Ç–∞ –ø–æ–ª—É—á–µ–Ω–∏—è'] = group['–î–∞—Ç–∞ –ø–æ–ª—É—á–µ–Ω–∏—è'].dt.tz_localize(None)
        except:
            pass
        # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º–æ–µ —Ä–∞–Ω–Ω–µ–µ –∏ —Å–∞–º–æ–µ –ø–æ–∑–¥–Ω–µ–µ –≤—Ä–µ–º—è –≤ –ø–µ—Ä–µ–ø–∏—Å–∫–µ
        min_received = group['–î–∞—Ç–∞ –ø–æ–ª—É—á–µ–Ω–∏—è'].min()
        min_sent = group['–î–∞—Ç–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏'].min()
        max_received = group['–î–∞—Ç–∞ –ø–æ–ª—É—á–µ–Ω–∏—è'].max()
        max_sent = group['–î–∞—Ç–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏'].max()
        if pd.isna(min_received):
            earliest = min_sent
        elif pd.isna(min_sent):
            earliest = min_received
        else:
            earliest = min(min_received, min_sent)
        if pd.isna(max_received):
            latest = max_sent
        elif pd.isna(max_sent):
            latest = max_received
        else:
            latest = max(max_received, max_sent)
        duration = (latest - earliest) if pd.notna(earliest) and pd.notna(latest) else pd.Timedelta(0)
        if duration >= pd.Timedelta(days=20):
            count_messages = len(group)
            # –ü—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å–Ω–∞—è —Ç–µ–º–∞ –ø–µ—Ä–µ–ø–∏—Å–∫–∏: –±–µ—Ä–µ–º —Ç–µ–º—É –ø–µ—Ä–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏
            rep_subject = group.sort_values(
                ['–î–∞—Ç–∞ –ø–æ–ª—É—á–µ–Ω–∏—è', '–î–∞—Ç–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏']).iloc[0]['–¢–µ–º–∞ —á–∏—Å—Ç–∞—è']
            stretched_list.append({
                'ConversationID': conv_id,
                '–¢–µ–º–∞ —á–∏—Å—Ç–∞—è': rep_subject,
                '–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å': duration,
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏—Å–µ–º': count_messages
            })
    stretched_df = pd.DataFrame(stretched_list)
    return stretched_df.sort_values(by='–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å', ascending=False).reset_index(drop=True)

def normalize_name(name):
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–º–µ–Ω–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞: —É–±—Ä–∞—Ç—å –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã, –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    name = ' '.join(str(name).strip().split())
    return name.lower()

def plot_department_traffic(incoming_summary, outgoing_summary):
    fig1, ax1 = plt.subplots(figsize=(6, 4))
    incoming_summary.sort_values().plot(kind='barh', ax=ax1, color='#1f77b4')
    ax1.set_title('–í—Ö–æ–¥—è—â–∏–µ –ø–∏—Å—å–º–∞', fontsize=10)
    ax1.set_xlabel('–ü–∏—Å–µ–º', fontsize=8)
    ax1.set_ylabel('–û—Ç–¥–µ–ª', fontsize=8)
    ax1.tick_params(axis='x', labelsize=7)
    ax1.tick_params(axis='y', labelsize=7)
    ax1.grid(axis='x')

    fig2, ax2 = plt.subplots(figsize=(6, 4))
    outgoing_summary.sort_values().plot(kind='barh', ax=ax2, color='#ff7f0e')
    ax2.set_title('–ò—Å—Ö–æ–¥—è—â–∏–µ –ø–∏—Å—å–º–∞', fontsize=10)
    ax2.set_xlabel('–ü–∏—Å–µ–º', fontsize=8)
    ax2.set_ylabel('–û—Ç–¥–µ–ª', fontsize=8)
    ax2.tick_params(axis='x', labelsize=7)
    ax2.tick_params(axis='y', labelsize=7)
    ax2.grid(axis='x')

    return fig1, fig2

# ========== Streamlit UI ==========

st.set_page_config(layout="wide")
st.title("–î–∞—à–±–æ—Ä–¥ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—á—Ç—ã —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞")

# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–∏—Å–µ–º
uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV-—Ñ–∞–π–ª —Å –≤—ã–≥—Ä—É–∑–∫–æ–π –ø–æ—á—Ç—ã", type="csv")
if uploaded_file:
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –∏ —Å—á–∏—Ç—ã–≤–∞–µ–º CSV —Å –ø–∏—Å—å–º–∞–º–∏
    delimiter = detect_delimiter(uploaded_file)
    df = pd.read_csv(uploaded_file, delimiter=delimiter, encoding='utf-8')
    df = preprocess(df)

    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –≥–æ–¥—É –∏ –Ω–µ–¥–µ–ª–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    years = sorted(df['–ì–æ–¥'].dropna().unique().tolist())
    weeks = sorted(df['–ù–µ–¥–µ–ª—è'].dropna().unique().tolist())
    selected_year = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ–¥", options=['–í—Å–µ'] + years)
    selected_week = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –Ω–µ–¥–µ–ª—é (–∏–ª–∏ '–í—Å–µ')", options=['–í—Å–µ'] + weeks)
    if selected_year != '–í—Å–µ':
        df = df[df['–ì–æ–¥'] == selected_year]
    if selected_week != '–í—Å–µ':
        df = df[df['–ù–µ–¥–µ–ª—è'] == selected_week]

    # 2. –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏ –≥—Ä–∞—Ñ–∏–∫–∏ –ø–æ –ø–∏—Å—å–º–∞–º
    st.subheader("üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–∏—Å–µ–º –ø–æ —Ä–æ–ª—è–º")
    role_counts = df['–†–æ–ª—å'].value_counts().reset_index().rename(columns={'index': '–†–æ–ª—å', '–†–æ–ª—å': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'})
    st.dataframe(role_counts)

    st.subheader("‚è±Ô∏è –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞")
    reply_df = reply_time_analysis(df)
    if not reply_df.empty:
        st.metric("–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ (—á)", round(reply_df['–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞'].mean(), 2))
        st.metric("–ú–µ–¥–∏–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ (—á)", round(reply_df['–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞'].median(), 2))

        # üîπ –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏—Å–µ–º –ø–æ –∫–∞–∂–¥–æ–π –ø–µ—Ä–µ–ø–∏—Å–∫–µ (ConversationID)
        message_counts = []
        for conv_id in reply_df['ConversationID'].unique():
            count = df[df['ConversationID'] == conv_id].shape[0]
            message_counts.append(count)

        if message_counts:
            st.metric("–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏—Å–µ–º –Ω–∞ –∏–Ω—Ü–∏–¥–µ–Ω—Ç", round(pd.Series(message_counts).mean(), 1))
            st.subheader("üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–∏—Å–µ–º –Ω–∞ –∏–Ω—Ü–∏–¥–µ–Ω—Ç")
            fig_msg, ax = plt.subplots(figsize=(8, 2))
            ax.hist(message_counts, bins=range(1, max(message_counts) + 2), edgecolor='black', align='left')
            ax.set_title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–∏—Å–µ–º –Ω–∞ –∏–Ω—Ü–∏–¥–µ–Ω—Ç", fontsize=10)
            ax.set_xlabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏—Å–µ–º", fontsize=8)
            ax.set_ylabel("–ß–∞—Å—Ç–æ—Ç–∞", fontsize=8)
            ax.tick_params(axis='x', labelsize=7)
            ax.tick_params(axis='y', labelsize=7)
            ax.grid(axis='y', linestyle='--', alpha=0.6)
            st.pyplot(fig_msg)

        st.metric("–ú–∏–Ω. –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ (—á)", round(reply_df['–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞'].min(), 2))
        st.metric("–ú–∞–∫—Å. –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ (—á)", round(reply_df['–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞'].max(), 2))

        message_counts = []
        for conv_id in reply_df['ConversationID'].unique():
            count = df[df['ConversationID'] == conv_id].shape[0]
            message_counts.append(count)

        if message_counts:
            st.metric("–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏—Å–µ–º –Ω–∞ –∏–Ω—Ü–∏–¥–µ–Ω—Ç", round(pd.Series(message_counts).mean(), 1))
            st.metric("–ú–µ–¥–∏–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏—Å–µ–º –Ω–∞ –∏–Ω—Ü–∏–¥–µ–Ω—Ç", round(pd.Series(message_counts).median(), 1))

        st.subheader("üì¨ –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –≥—Ä–∞—Ñ–∏–∫–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞")
        col1, col2 = st.columns(2)
        with col1:
            st.pyplot(plot_reply_distribution(reply_df['–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞']))
        with col2:
            st.pyplot(plot_weekly_trends(reply_df))
    else:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞.")

    col1, col2 = st.columns(2)
    with col1:
        st.pyplot(plot_weekly_message_flow(df))
    with col2:
        st.pyplot(plot_weekly_claims(df))

    st.subheader("üìå –†–∞—Å—Ç—è–Ω—É—Ç—ã–µ —Ç–µ–º—ã (–ø–µ—Ä–µ–ø–∏—Å–∫–∞ –¥–ª–∏–ª–∞—Å—å ‚â•20 –¥–Ω–µ–π)")
    stretched_df = stretch_topics(df)
    st.dataframe(stretched_df.head(10))

    selected_topic = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–µ–º—É –¥–ª—è –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–µ—Ä–µ–ø–∏—Å–∫–∏", options=stretched_df['–¢–µ–º–∞ —á–∏—Å—Ç–∞—è'] if not stretched_df.empty else [])
    if selected_topic:
        st.subheader("üì• –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–ø–∏—Å–∫–∏ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–π —Ç–µ–º–µ")
        # –ù–∞—Ö–æ–¥–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π ConversationID –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π —Ç–µ–º—ã
        conv_ids = stretched_df[stretched_df['–¢–µ–º–∞ —á–∏—Å—Ç–∞—è'] == selected_topic]['ConversationID'].tolist()
        if conv_ids:
            conv_id = conv_ids[0]
            topic_messages = df[df['ConversationID'] == conv_id][[
                '–î–∞—Ç–∞ –ø–æ–ª—É—á–µ–Ω–∏—è', '–î–∞—Ç–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏', '–û—Ç –∫–æ–≥–æ', '–ö–æ–º—É', '–ö–æ–ø–∏—è', '–¢–µ–º–∞', '–†–æ–ª—å'
            ]]
            st.dataframe(topic_messages.sort_values(by='–î–∞—Ç–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏'))
        else:
            st.info("–ü–µ—Ä–µ–ø–∏—Å–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")

    st.subheader("‚ö† –ü–∏—Å—å–º–∞ —Å –æ—Ç–≤–µ—Ç–æ–º –ø–æ–∑–∂–µ 3 —Ä–∞–±–æ—á–∏—Ö –¥–Ω–µ–π")
    late_replies = reply_df[reply_df['–ü—Ä–æ—Å—Ä–æ—á–∫–∞'] == True]
    if not late_replies.empty:
        st.dataframe(late_replies[['–¢–µ–º–∞', '–î–∞—Ç–∞ –≤—Ö–æ–¥—è—â–µ–≥–æ', '–î–∞—Ç–∞ –æ—Ç–≤–µ—Ç–∞', '–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞', '–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ (–¥–Ω–µ–π)']])
    else:
        st.success("–í—Å–µ –≤—Ö–æ–¥—è—â–∏–µ –ø–∏—Å—å–º–∞ –±—ã–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –≤–æ–≤—Ä–µ–º—è.")

    # 3. –ê–Ω–∞–ª–∏–∑ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π –ø–æ –æ—Ç–¥–µ–ª–∞–º (–æ—Ç–¥–µ–ª—å–Ω—ã–π –±–ª–æ–∫)
    st.subheader("üì® –ê–Ω–∞–ª–∏–∑ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π –ø–æ –æ—Ç–¥–µ–ª–∞–º")
    employees_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV-—Ñ–∞–π–ª —Å–æ —Å–ø–∏—Å–∫–æ–º —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤", type="csv")
    if employees_file:
        # –°—á–∏—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ —Å –∞–≤—Ç–æ-–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è
        delim_emp = detect_delimiter(employees_file)
        employees_df = pd.read_csv(employees_file, delimiter=delim_emp, encoding='utf-8')
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –§–ò–û —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
        employees_df['–§–ò–û_–Ω–æ—Ä–º'] = employees_df['–§–ò–û'].apply(normalize_name)

        # –°–±–æ—Ä –≤—Å–µ—Ö –∏–º–µ–Ω (–≤—Ö–æ–¥—è—â–∞—è –ø–æ—á—Ç–∞: –û—Ç –∫–æ–≥–æ, –ö–æ–º—É, –ö–æ–ø–∏—è)
        all_names = []
        for col in ['–û—Ç –∫–æ–≥–æ', '–ö–æ–º—É', '–ö–æ–ø–∏—è']:
            df[col] = df[col].fillna("")
            for entry in df[col]:
                parts = str(entry).split(';')
                for name in parts:
                    norm_name = normalize_name(name)
                    if norm_name and '–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö' not in norm_name and '@' not in norm_name:
                        all_names.append(norm_name)
        name_counts = Counter(all_names)
        name_df = pd.DataFrame(name_counts.items(), columns=['–§–ò–û_–Ω–æ—Ä–º', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏—Å–µ–º'])

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è–º–∏ –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º
        merged_df = name_df.merge(employees_df[['–§–ò–û_–Ω–æ—Ä–º', '–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ']], on='–§–ò–û_–Ω–æ—Ä–º', how='left')
        filtered_df = merged_df.dropna(subset=['–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ'])
        filtered_df_no_claims = filtered_df[filtered_df['–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ'].str.lower() != '–ø—Ä–µ—Ç–µ–Ω–∑–∏–æ–Ω–Ω—ã–π –æ—Ç–¥–µ–ª']

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –æ—Ç–¥–µ–ª–∞–º ‚Äì –≤—Ö–æ–¥—è—â–∏–µ –ø–∏—Å—å–º–∞ (–¥–ª—è —Ç–æ–ø-10 –æ—Ç–¥–µ–ª–æ–≤)
        department_summary_no_claims = (
            filtered_df_no_claims.groupby('–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ')['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏—Å–µ–º']
            .sum()
            .sort_values(ascending=False)
            .head(10)
        )

        # –°–±–æ—Ä –≤—Å–µ—Ö –∏–º–µ–Ω –∞–¥—Ä–µ—Å–∞—Ç–æ–≤ (–∏—Å—Ö–æ–¥—è—â–∞—è –ø–æ—á—Ç–∞: –ö–æ–º—É –∏ –ö–æ–ø–∏—è)
        outgoing_names = []
        for col in ['–ö–æ–º—É', '–ö–æ–ø–∏—è']:
            for entry in df[col]:
                parts = str(entry).split(';')
                for name in parts:
                    norm_name = normalize_name(name)
                    if norm_name and '–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö' not in norm_name and '@' not in norm_name:
                        outgoing_names.append(norm_name)
        outgoing_counts = Counter(outgoing_names)
        outgoing_df = pd.DataFrame(outgoing_counts.items(), columns=['–§–ò–û_–Ω–æ—Ä–º', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏—Å–µ–º'])
        outgoing_merged = outgoing_df.merge(employees_df[['–§–ò–û_–Ω–æ—Ä–º', '–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ']], on='–§–ò–û_–Ω–æ—Ä–º', how='left')
        outgoing_filtered = outgoing_merged.dropna(subset=['–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ'])
        outgoing_filtered = outgoing_filtered[outgoing_filtered['–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ'].str.lower() != '–ø—Ä–µ—Ç–µ–Ω–∑–∏–æ–Ω–Ω—ã–π –æ—Ç–¥–µ–ª']

        outgoing_summary = (
            outgoing_filtered.groupby('–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ')['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏—Å–µ–º']
            .sum()
            .sort_values(ascending=False)
            .head(10)
        )

        # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –≥—Ä–∞—Ñ–∏–∫–æ–≤ —Ç–æ–ø-10 –æ—Ç–¥–µ–ª–æ–≤ –¥–ª—è –≤—Ö–æ–¥—è—â–µ–π –∏ –∏—Å—Ö–æ–¥—è—â–µ–π –ø–æ—á—Ç—ã
        fig1, fig2 = plot_department_traffic(department_summary_no_claims, outgoing_summary)
        col1, col2 = st.columns(2)
        with col1:
            st.pyplot(fig1)
        with col2:
            st.pyplot(fig2)
    else:
        st.info("üëâ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å–æ —Å–ø–∏—Å–∫–æ–º —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–π –ø–æ –æ—Ç–¥–µ–ª–∞–º.")
